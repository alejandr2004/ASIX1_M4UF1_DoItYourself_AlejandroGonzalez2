<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Document</title>
    <link rel="stylesheet" type="text/css" href="./hojaexterna.css">



</head>
<body>
<h3>La generación del lenguaje en las máquinas</h3>
 

<p>Una vez que he formulado los principios básicos de cómo se articula el lenguaje humano, pensemos en qué hacen 
y cómo lo hacen los modelos de lenguaje natural. Adelanto <span>que no soy una experta en el tema</span>, pero lo que parece 
evidente es que estos modelos son capaces de elaborar textos con una cohesión y coherencia tan apabullantes que, 
realmente, pareciera que hablaran. Lo que quizás no resulte tan evidente es que no tienen ni la más remota idea 
de lo que están diciendo, por un lado, y que el hecho de que sus producciones sean gramaticales se debe a una 
cuestión matemática y no lingüística. Me explico a continuación.</p>

<p>He mencionado anteriormente que el punto de partida en la formación de todas nuestras producciones lingüísticas 
son los ítem léxicos o palabras. ChatGPT no trabaja con palabras ni con ítems léxicos, sino con lo que se denomina 
tokens que son, grosso modo, conjuntos de letras (dado que es un modelo escrito) que se combinan matemáticamente.</p>

<p>Según cuenta de manera magistral José Luis Mendívil en el artículo “Un loro estocástico en la habitación china: 
¿qué nos enseña ChatGPT sobre la mente humana”, estos modelos de generación de lenguaje se limitan a crear, de 
forma lineal<div>(insisto en que crean de forma lineal y no jerárquica, como lo hace el lenguaje humano)</div> , cadenas de 
palabras a partir de modelos matemáticos; es decir, que analizan un conjunto enorme de textos para ser capaces de 
mostrar qué palabra aparecerá detrás de la que ya han escrito.</p>

<p>Sin duda, la aparición de estos modelos supone un <strong>avance enorme</strong> para el acceso al conocimiento. ChatGPT es capaz de 
explicarnos de forma muy detallada conceptos sencillos y cuya información está recogida en algún punto de los conjuntos 
de textos con los que trabaja. Lo que ya no hace tan bien este modelo de lenguaje es crear nuevas emisiones o interpretar 
las producidas y, mucho menos, es capaz de determinar si una producción es o no posible en una lengua. Pondré un ejemplo. 
Le he preguntado a ChatGPT lo siguiente:
<h5>Pregunta a ChatGPT. Silvia Gumiel / TELOS</h5></p>
<img src="./imagen1.PNG" alt="">
<ul>Diferencia entre joven y viejo</ul>
<p>Como se puede observar por la respuesta, este modelo del lenguaje no es capaz de comprender la diferencia entre dos emisiones 
que un niño de seis años entiende perfectamente (su respuesta es errónea, la interpretación que hace un humano es exactamente 
la contraria). Y la razón es fundamentalmente que las IA de procesamiento de textos no entienden ni lo que están diciendo ni 
cómo están construyendo su “lenguaje” mientras que un ser humano, de manera inconsciente, sabe que un joven viejo es un sintagma 
nominal cuyo núcleo es joven (por tanto, un joven viejo es un tipo de joven) mientras que en un viejo joven el núcleo es viejo y, 
por tanto, nos referimos a un tipo de viejo.</p>

<p>Avancemos un poco más. Le he pedido a ChatGPT que cree una oración agramatical. Esta ha sido su respuesta:
Pregunta a ChatGPT. Silvia Gumiel / TELOS</p>
<img src="./imagen2.PNG" alt="">
<ul>Oración agramatical</ul>
<p>Aunque a priori podría parecer que tiene razón, lo cierto es que los pájaros volar podría ser una oración bien 
formada en algunos contextos, aunque no haya concordancia entre el sujeto y el verbo 
(que no puede concordar porque está en infinitivo) como, por ejemplo: me gusta ver los pájaros volar. 
Lo que, de hecho, hace agramatical esa secuencia es que el determinante no concuerda con el nombre al que modifica 
y no la falta de concordancia entre sujeto y predicado.</p>

<p>Sirvan estos dos ejemplos para mostrar que estas IA no solo no hablan, sino que <strong> son capaces de entender ni lo que dicen 
ni lo que se les dice</strong>. Con toda seguridad, estos modelos se irán mejorando, pero creo que puedo afirmar sin equivocarme que,
mientras se basen en modelos matemáticos y su implementación no esté fundamentada en los principios que articulan la arquitectura 
del lenguaje humano, no será posible que generen lenguaje natural y, mucho menos, que lo entiendan.</p>

<p>Esto no quiere decir que estos modelos no sean un instrumento fantástico para avanzar en el conocimiento. Pero también lo serán para retroceder si no los utilizamos adecuadamente. 
Una vez que he formulado los principios básicos de cómo se articula el lenguaje humano, pensemos en qué hacen 
y cómo lo hacen los modelos de lenguaje natural.</p> 

<p>He mencionado anteriormente que el punto de partida en la formación de todas nuestras producciones lingüísticas son 
los ítem léxicos o palabras. ChatGPT no trabaja con palabras ni con ítems léxicos, sino con lo que se denomina tokens 
que son, grosso modo, conjuntos de letras (dado que es un modelo escrito) que se combinan matemáticamente.</p>
  
</body>
</html>
